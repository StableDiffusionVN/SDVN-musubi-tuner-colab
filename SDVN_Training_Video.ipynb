{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iUUqhJBwbNW"
   },
   "source": [
    "# [![](https://img.shields.io/badge/Musubi-Tuner-Blue)](https://github.com/kohya-ss/sd-scripts/tree/sd3?tab=readme-ov-file#flux1-fine-tuning) [![](https://img.shields.io/badge/Video-HÆ°á»›ng%20dáº«n-ff0000)](https://youtu.be/798qchqWty4) [![](https://img.shields.io/badge/Design-stablediffusion.vn-0075ff)](https://stablediffusion.vn) [![](https://img.shields.io/badge/Ver-1.0-0075ff)](https://trainlora.vn) [![](https://img.shields.io/badge/All%20Tools-trainlora.vn-0075ff)](https://trainlora.vn) [![](https://img.shields.io/badge/SDVN-Library-green)](https://bit.ly/sdvn-lib) [![](https://img.shields.io/badge/KhoÃ¡%20há»c-All%20in%20one-red)](https://hungdiffusion.com/) [![](https://img.shields.io/badge/Group-Support-0075ff)](https://www.facebook.com/groups/stablediffusion.vn) [![](https://img.shields.io/discord/813085864355037235?color=blue&label=Discord&logo=Discord)](https://discord.gg/5SEtApPeyG)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXK9gCuIvzvs"
   },
   "source": [
    "#âš™ï¸ I. CÃ i Ä‘áº·t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133507,
     "status": "ok",
     "timestamp": 1743341339402,
     "user": {
      "displayName": "Pháº¡m HÆ°ng SDVN",
      "userId": "02806797931478696703"
     },
     "user_tz": -420
    },
    "id": "br2-uOpChoEp",
    "outputId": "fb6eca2b-29e2-4992-ea1f-c9bd307941e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Cloning into 'musubi-tuner'...\n",
      "remote: Enumerating objects: 1033, done.\u001b[K\n",
      "remote: Counting objects: 100% (477/477), done.\u001b[K\n",
      "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
      "remote: Total 1033 (delta 374), reused 321 (delta 318), pack-reused 556 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1033/1033), 585.88 KiB | 5.42 MiB/s, done.\n",
      "Resolving deltas: 100% (668/668), done.\n",
      "/content/musubi-tuner\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m447.8/447.8 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m125.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# @title ###Install\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "root_dir = \"/content/\"\n",
    "data_dir = \"/content/drive/MyDrive/SD-Data\"\n",
    "repo_dir = \"/content/SDVN-musubi-tuner-colab\"\n",
    "\n",
    "if not os.path.exists(\"/content/musubi-tuner\"):\n",
    "  %cd /content\n",
    "  !git clone https://github.com/StableDiffusionVN/SDVN-musubi-tuner-colab\n",
    "  !git clone https://github.com/kohya-ss/musubi-tuner\n",
    "  %cd /content/musubi-tuner\n",
    "  !sed -i 's/^bitsandbytes==0.45.0/bitsandbytes/' /content/musubi-tuner/requirements.txt\n",
    "  !pip install -q -r /content/musubi-tuner/requirements.txt\n",
    "  !pip install -q toml aria2 OpenAI google-genai flash_attn==2.7.3\n",
    "\n",
    "%cd /content\n",
    "%run {repo_dir}/TrainScript.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJM2WBVLlkzZ"
   },
   "source": [
    "# ğŸšï¸ II. Config Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7402,
     "status": "ok",
     "timestamp": 1743341351597,
     "user": {
      "displayName": "Pháº¡m HÆ°ng SDVN",
      "userId": "02806797931478696703"
     },
     "user_tz": -420
    },
    "id": "HYytXyzlj6PT",
    "outputId": "ff1be06d-f0c6-44e8-f77b-f00ad6f4e3c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_latent_cache\n",
      "cache\n",
      "cache_wan_i2v\n",
      "cache_hun_t2v\n",
      "cache\n",
      "cache_wan_i2v\n",
      ".ipynb_checkpoints\n",
      "cache_wan_t2v\n",
      "cache_hun_t2v\n"
     ]
    }
   ],
   "source": [
    "#@title ğŸ“‚ 2. Káº¿t ná»‘i - xá»­ lÃ½ data\n",
    "\n",
    "Image_train = True #@param {type:\"boolean\"}\n",
    "ImageFolder = \"/content/drive/Shareddrives/StableDiffusion/TrainData/test\"  # @param {type:'string'}\n",
    "Video_train = False #@param {type:\"boolean\"}\n",
    "VideoFolder = \"/content/drive/Shareddrives/StableDiffusion/TrainData/test_video\"  # @param {type:'string'}\n",
    "DataClean = False #@param {type:\"boolean\"}\n",
    "No_gen_caption = False #@param {type:\"boolean\"}\n",
    "# @markdown ğŸŸ¡ `OCR Prompt`\n",
    "\n",
    "# @markdown ğŸ’¡ `Florence yÃªu cáº§u khá»Ÿi Ä‘á»™ng láº¡i phiÃªn (Ctr + M + .) vÃ  cháº¡y láº¡i tá»« Ä‘áº§u`\n",
    "\n",
    "# @markdown ğŸ’¡ `Táº¡o caption tá»± Ä‘á»™ng cho video chá»‰ há»— trá»£ dÃ¹ng api qua gemini`\n",
    "Caption_Image = 'None' # @param ['None', 'Florence', 'APIGemini | 2.0 Flash', 'APIGemini | 2.0 Flash Lite', 'APIOpenAI | GPT 4-o mini']\n",
    "Caption_Video = 'None' # @param ['None','APIGemini | 2.0 Flash', 'APIGemini | 2.0 Flash Lite']\n",
    "Caption_Length = \"Medium\" # @param [\"Short\",\"Medium\",\"Long\"]\n",
    "# @markdown ğŸŸ¡ `API Caption`\n",
    "\n",
    "# @markdown [![](https://img.shields.io/badge/Gemini-API-blue)](https://aistudio.google.com/app/apikey)\n",
    "APIkey = \"\" # @param {type:'string'}\n",
    "API_Prompt = \"\" # @param {type:'string'}\n",
    "# @markdown ğŸŸ¡ `ThÃªm caption tuá»³ chá»n`\n",
    "Custom_Caption = \"\" # @param {type:'string'}\n",
    "AddFolderName = False #@param {type:\"boolean\"}\n",
    "Remove_Caption = False #@param {type:\"boolean\"}\n",
    "Append = False #@param {type:\"boolean\"}\n",
    "\n",
    "if No_gen_caption == True:\n",
    "  Caption = 'None'\n",
    "  Custom_Caption = ''\n",
    "  AddFolderName = False\n",
    "\n",
    "Cap_prompt = {\n",
    "    'Short':['<CAPTION>',0.85, 30],\n",
    "    'Medium':['<DETAILED_CAPTION>',0.5, 60],\n",
    "    'Long':['<MORE_DETAILED_CAPTION>',0.35, 100]\n",
    "}\n",
    "extension = \".txt\"\n",
    "\n",
    "if DataClean == True :\n",
    "  %cd /content\n",
    "  clean_directory(ImageFolder)\n",
    "if Caption_Image != \"None\":\n",
    "  caption_dir(ImageFolder,Cap_prompt[Caption_Length])\n",
    "\n",
    "if Caption_Video != \"None\":\n",
    "  caption_dir(VideoFolder,Cap_prompt[Caption_Length], True)\n",
    "\n",
    "list_train_dir = []\n",
    "if Image_train:\n",
    "  list_train_dir.append(ImageFolder)\n",
    "if Video_train:\n",
    "  list_train_dir.append(VideoFolder)\n",
    "if AddFolderName:\n",
    "  for dir in list_train_dir:\n",
    "    add_forder_name(dir)\n",
    "if Custom_Caption != \"\":\n",
    "  for dir in list_train_dir:\n",
    "    process_dir(dir, Custom_Caption, Append, Remove_Caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155,
     "status": "ok",
     "timestamp": 1743344226733,
     "user": {
      "displayName": "Pháº¡m HÆ°ng SDVN",
      "userId": "02806797931478696703"
     },
     "user_tz": -420
    },
    "id": "Qut3j_jv8YZW",
    "outputId": "5ec1c2a5-96d1-4161-b105-537aa57fc67c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate launch --mixed_precision bf16 --num_cpu_threads_per_process 1    wan_train_network.py  --task i2v-14B --dit \"/content/models/wan2.1_i2v_720p_14B_fp8_e4m3fn.safetensors\" --dataset_config \"/content/dataset.toml\" --sdpa          --split_attn  --mixed_precision bf16 --fp8_base  --optimizer_type adamw8bit   --learning_rate 0.0001 --lr_scheduler constant --gradient_checkpointing    --max_data_loader_n_workers 2 --persistent_data_loader_workers  --network_module networks.lora_wan --network_dim 32 --network_alpha 32     --timestep_sampling shift --discrete_flow_shift 3.0   --max_train_epochs 10 --save_every_n_epochs 2     --seed 42 --output_dir \"/content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v\" --output_name \"test_vivi\"  --vae \"/content/models/wan_2.1_vae.safetensors\" --t5 \"/content/models/models_t5_umt5-xxl-enc-bf16.pth\"     --clip \"/content/models/models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth\" --sample_prompts \"/content/prompt.txt\"   --sample_every_n_steps 200 --sample_at_first  --log_with wandb --wandb_api_key b037424918f8e39bdbea8dd24561aed45985ece9 --wandb_run_name \"wan_i2v_test_vivi\" --save_state      --metadata_title \"test_vivi\" --metadata_author \"stablediffusion.vn\" --metadata_description \"phamhung sdvn.me training\"     \n",
      "python    wan_cache_latents.py  --dataset_config \"/content/dataset.toml\" --vae \"/content/models/wan_2.1_vae.safetensors\"     --clip \"/content/models/models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth\" \n",
      "python    wan_cache_text_encoder_outputs.py  --dataset_config \"/content/dataset.toml\"     --t5 \"/content/models/models_t5_umt5-xxl-enc-bf16.pth\" --batch_size 16 \n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#@title ğŸ› ï¸ 3. Cáº¥u hÃ¬nh train\n",
    "\n",
    "%run {repo_dir}/Config.ipynb\n",
    "\n",
    "model_train = \"wan_i2v\" # @param [\"wan_t2v\", \"wan_i2v\", \"wan_t2v_13\", \"hun_t2v\"]\n",
    "output_dir = \"/content/drive/Shareddrives/StableDiffusion/Lora\" # @param {type:'string'}\n",
    "output_name = \"test_vivi\" # @param {type:'string'}\n",
    "#value\n",
    "# @markdown ğŸ’¡ `Tuá»³ chá»‰nh theo tá»‰ lá»‡ khung hÃ¬nh vÃ  lÆ°á»£ng frame. Train hÃ¬nh tÆ°Æ¡ng Ä‘Æ°Æ¡ng frame = 1`\n",
    "resolution = \"720,480\" # @param {type:'string'}\n",
    "batch_size = 1 # @param {type:'number'}\n",
    "image_dir = ImageFolder\n",
    "video_dir = VideoFolder\n",
    "num_repeats = 50 # @param {type:'number'}\n",
    "# @markdown ğŸ’¡ `CÃ¡c cháº¿ Ä‘á»™ xá»­ lÃ½ video`\n",
    "\n",
    "# @markdown â–ªï¸ `head - Láº¥y trá»±c tiáº¿p cÃ¡c frame tá»« Ä‘áº§u vá»›i lÆ°á»£ng frame = target_frames`\n",
    "\n",
    "# @markdown â–ªï¸ `chunk - Chia video thÃ nh tá»«ng Ä‘oáº¡n theo vá»›i lÆ°á»£ng frame = target_frames`\n",
    "\n",
    "# @markdown â–ªï¸ `slide - TrÃ­ch frame = target_frames vÃ  cÃ¡ch nhau frame_stride`\n",
    "\n",
    "# @markdown â–ªï¸ `uniform - Chia Ä‘á»u video thÃ nh frame_sample Ä‘oáº¡n, má»—i Ä‘oáº¡n trÃ­ch suáº¥t frame = target_frames`\n",
    "\n",
    "# @markdown â–ªï¸ `full - TrÃ­ch xuáº¥t toÃ n bá»™ video vÃ  giá»›i háº¡n khÃ´ng quÃ¡ max_frames`\n",
    "\n",
    "# @markdown ğŸ’¡ `target_frames - LÆ°á»£ng frame Ä‘Æ°á»£c cáº¯t | VD:1,25,33 - 3 phÆ°Æ¡ng Ã¡n vá»›i 1, 25, 33 frame`\n",
    "\n",
    "frame_extraction = \"head\" # @param [\"head\",\"chunk\",\"slide\",\"uniform\",\"full\"]\n",
    "target_frames = \"1,25,33\" # @param {type:'string'}\n",
    "frame_stride = 1 # @param {type:'number'}\n",
    "frame_sample = 1 # @param {type:'number'}\n",
    "max_frames = 33 # @param {type:'number'}\n",
    "\n",
    "# @markdown *ï¸âƒ£ `Äiá»u chá»‰nh Learning Rate`\n",
    "learning_rate = 1e-4 # @param {type:'number'}\n",
    "optimizer_type = \"adamw8bit\" # @param [\"adamw\", \"adamw8bit\", \"adafactor\"]\n",
    "lr_scheduler = \"constant\" # @param [ \"cosine\", \"constant\", \"polynomial\"]\n",
    "network_dim = 32 # @param {type:'number'}\n",
    "network_alpha = 32 # @param {type:'number'}\n",
    "max_train_epochs = 10 # @param {type:'number'}\n",
    "save_every_n_epochs = 2 # @param {type:'number'}\n",
    "save_last_n_epochs = 0 # @param {type:'number'}\n",
    "save_every_n_steps = 0 # @param {type:'number'}\n",
    "# @markdown *ï¸âƒ£ `Báº­t/Táº¯t cÃ¡c tÃ­nh nÄƒng má»Ÿ rá»™ng, bao gá»“m (info, sampler, sao lÆ°u, log)`\n",
    "extra_option = True #@param {type:\"boolean\"}\n",
    "author = 'stablediffusion.vn' # @param {\"type\":\"string\"}\n",
    "description = 'phamhung sdvn.me training' # @param {\"type\":\"string\"}\n",
    "sample_prompt = \"\" #@param {type:'string'}\n",
    "sample_size = \"512,512\" #@param {type:'string'}\n",
    "sample_every_n_steps = 200 # @param {type:'number'}\n",
    "# @markdown ğŸŸ¡ `Train model i2v (Image to video) sáº½ cáº§n má»™t áº£nh frame Ä‘áº§u Ä‘á»ƒ cháº¡y Ä‘Æ°á»£c sample`\n",
    "sample_image_i2v_path = \"\" #@param {type:'string'}\n",
    "wandb_api_key = '' #@param {type:'string'}\n",
    "save_state = False #@param {type:\"boolean\"}\n",
    "save_state_on_train_end = False #@param {type:\"boolean\"}\n",
    "resume = \"\" #@param {type:'string'}\n",
    "\n",
    "#default\n",
    "\n",
    "resolution = [int(x) for x in resolution.split(\",\")]\n",
    "target_frames = [int(x) for x in target_frames.split(\",\")]\n",
    "dataset = os.path.join(root_dir,\"dataset.toml\")\n",
    "\n",
    "data_config = data_config(resolution, extension, batch_size)\n",
    "dataset_file(Image_train, Video_train, image_dir, data_config, video_dir, model_train, num_repeats, frame_extraction, target_frames, frame_stride, frame_sample, max_frames)\n",
    "config = config(model_train, optimizer_type, learning_rate, lr_scheduler, network_dim, network_alpha, max_train_epochs, save_every_n_epochs, save_last_n_epochs, save_every_n_steps, output_dir, output_name)\n",
    "extra = extra(model_train, sample_every_n_steps, wandb_api_key, output_name, save_state, save_state_on_train_end, resume, author, description)\n",
    "folder_train = ImageFolder if Image_train else VideoFolder\n",
    "prompt(model_train, sample_prompt, folder_train, sample_image_i2v_path)\n",
    "cache_latents_config = cache_latents_config(model_train)\n",
    "cache_text_encoder_config = cache_text_encoder_config(model_train)\n",
    "\n",
    "arg = f'accelerate launch {dic2arg(op)} {dic2arg(config)} {dic2arg(extra) if extra_option else \"\"}'\n",
    "print(arg)\n",
    "arg_latents_config = dic2arg(cache_latents_config)\n",
    "print(arg_latents_config)\n",
    "arg_text_encoder_config = dic2arg(cache_text_encoder_config)\n",
    "print(arg_text_encoder_config)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STDQ7a1pl4pR"
   },
   "source": [
    "# â³ III. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5s2v4fIiGXH",
    "outputId": "49287405-8204-47f7-86c4-227eaa15fd8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/musubi-tuner\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "2025-03-30 14:17:17.538210: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-30 14:17:17.556245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743344237.578448   14104 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743344237.585120   14104 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-30 14:17:17.607491: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Trying to import sageattention\n",
      "Failed to import sageattention\n",
      "INFO:wan.modules.model:Detected DiT dtype: torch.float8_e4m3fn\n",
      "INFO:hv_train_network:Load dataset config from /content/dataset.toml\n",
      "INFO:dataset.image_video_dataset:glob images in /content/drive/Shareddrives/StableDiffusion/TrainData/test\n",
      "INFO:dataset.image_video_dataset:found 10 images\n",
      "INFO:dataset.image_video_dataset:glob videos in /content/drive/Shareddrives/StableDiffusion/TrainData/test_video\n",
      "INFO:dataset.image_video_dataset:found 1 videos\n",
      "INFO:dataset.config_utils:[Dataset 0]\n",
      "  is_image_dataset: True\n",
      "  resolution: (720, 480)\n",
      "  batch_size: 1\n",
      "  num_repeats: 50\n",
      "  caption_extension: \".txt\"\n",
      "  enable_bucket: True\n",
      "  bucket_no_upscale: False\n",
      "  cache_directory: \"/content/cache_wan_i2v\"\n",
      "  debug_dataset: False\n",
      "    image_directory: \"/content/drive/Shareddrives/StableDiffusion/TrainData/test\"\n",
      "    image_jsonl_file: \"None\"\n",
      "\n",
      "[Dataset 1]\n",
      "  is_image_dataset: False\n",
      "  resolution: (720, 480)\n",
      "  batch_size: 1\n",
      "  num_repeats: 50\n",
      "  caption_extension: \".txt\"\n",
      "  enable_bucket: True\n",
      "  bucket_no_upscale: False\n",
      "  cache_directory: \"/content/drive/Shareddrives/StableDiffusion/TrainData/test_video/cache_wan_i2v\"\n",
      "  debug_dataset: False\n",
      "    video_directory: \"/content/drive/Shareddrives/StableDiffusion/TrainData/test_video\"\n",
      "    video_jsonl_file: \"None\"\n",
      "    control_directory: \"None\"\n",
      "    target_frames: (1, 25, 33)\n",
      "    frame_extraction: head\n",
      "    frame_stride: 1\n",
      "    frame_sample: 1\n",
      "    max_frames: 33\n",
      "\n",
      "\n",
      "INFO:dataset.image_video_dataset:bucket: (480, 720), count: 450\n",
      "INFO:dataset.image_video_dataset:bucket: (672, 512), count: 50\n",
      "INFO:dataset.image_video_dataset:total batches: 500\n",
      "INFO:dataset.image_video_dataset:bucket: (768, 448, 1), count: 50\n",
      "INFO:dataset.image_video_dataset:bucket: (768, 448, 25), count: 50\n",
      "INFO:dataset.image_video_dataset:bucket: (768, 448, 33), count: 50\n",
      "INFO:dataset.image_video_dataset:total batches: 150\n",
      "INFO:hv_train_network:preparing accelerator\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mphamhung-d\u001b[0m (\u001b[33mphamhungd\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "accelerator device: cuda\n",
      "INFO:hv_train_network:DiT precision: torch.bfloat16, weight precision: torch.float8_e4m3fn\n",
      "INFO:__main__:cache Text Encoder outputs for sample prompt: /content/prompt.txt\n",
      "INFO:__main__:loading T5: /content/models/models_t5_umt5-xxl-enc-bf16.pth\n",
      "INFO:wan.modules.t5:loading weights from /content/models/models_t5_umt5-xxl-enc-bf16.pth\n",
      "INFO:wan.modules.t5:moving model to cuda and casting to torch.bfloat16\n",
      "INFO:__main__:encoding with Text Encoder 1\n",
      "INFO:__main__:cache Text Encoder outputs for prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:__main__:cache Text Encoder outputs for prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:__main__:loading CLIP: /content/models/models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth\n",
      "INFO:root:loading /content/models/models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth\n",
      "INFO:root:weights loaded from /content/models/models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth: <All keys matched successfully>\n",
      "INFO:__main__:Encoding image to CLIP context\n",
      "INFO:__main__:Encoding image: /content/imageanime.png\n",
      "INFO:__main__:Loading VAE model from /content/models/wan_2.1_vae.safetensors\n",
      "INFO:root:loading /content/models/wan_2.1_vae.safetensors\n",
      "INFO:hv_train_network:Loading DiT model from /content/models/wan2.1_i2v_720p_14B_fp8_e4m3fn.safetensors\n",
      "INFO:wan.modules.model:Creating WanModel\n",
      "INFO:wan.modules.model:Loading DiT model from /content/models/wan2.1_i2v_720p_14B_fp8_e4m3fn.safetensors, device=cuda, dtype=torch.float8_e4m3fn\n",
      "INFO:wan.modules.model:Loaded DiT model from /content/models/wan2.1_i2v_720p_14B_fp8_e4m3fn.safetensors, info=<All keys matched successfully>\n",
      "import network module: networks.lora_wan\n",
      "INFO:networks.lora:create LoRA network. base dim (rank): 32, alpha: 32.0\n",
      "INFO:networks.lora:neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
      "INFO:networks.lora:create LoRA for U-Net/DiT: 480 modules.\n",
      "INFO:networks.lora:enable LoRA for U-Net: 480 modules\n",
      "WanModel: Gradient checkpointing enabled.\n",
      "prepare optimizer, data loader etc.\n",
      "INFO:hv_train_network:use 8-bit AdamW optimizer | {}\n",
      "override steps. steps for 10 epochs is / æŒ‡å®šã‚¨ãƒãƒƒã‚¯ã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°: 6500\n",
      "INFO:hv_train_network:casting model to torch.float8_e4m3fn\n",
      "running training / å­¦ç¿’é–‹å§‹\n",
      "  num train items / å­¦ç¿’ç”»åƒã€å‹•ç”»æ•°: 650\n",
      "  num batches per epoch / 1epochã®ãƒãƒƒãƒæ•°: 650\n",
      "  num epochs / epochæ•°: 10\n",
      "  batch size per device / ãƒãƒƒãƒã‚µã‚¤ã‚º: 1, 1\n",
      "  gradient accumulation steps / å‹¾é…ã‚’åˆè¨ˆã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—æ•° = 1\n",
      "  total optimization steps / å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—æ•°: 6500\n",
      "INFO:hv_train_network:set DiT model name for metadata: /content/models/wan2.1_i2v_720p_14B_fp8_e4m3fn.safetensors\n",
      "INFO:hv_train_network:set VAE model name for metadata: /content/models/wan_2.1_vae.safetensors\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/musubi-tuner/wandb/run-20250330_141753-8oyzuyne\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwan_i2v_test_vivi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/phamhungd/network_train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/phamhungd/network_train/runs/8oyzuyne\u001b[0m\n",
      "steps:   0% 0/6500 [00:00<?, ?it/s]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 0\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:04,  3.41s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<01:00,  3.35s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:10<00:56,  3.33s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:53,  3.32s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:33<00:33,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:43<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:06<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "INFO:hv_train_network:DiT dtype: torch.float8_e4m3fn, device: cuda:0\n",
      "\n",
      "epoch 1/10\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 0, epoch: 1\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 0, epoch: 1\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 0, epoch: 1\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 0, epoch: 1\n",
      "steps:   3% 200/6500 [10:22<5:26:58,  3.11s/it, avr_loss=0.00942]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 200\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:   6% 400/6500 [20:19<5:09:58,  3.05s/it, avr_loss=0.00826]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 400\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:   9% 600/6500 [29:37<4:51:21,  2.96s/it, avr_loss=0.00734]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 600\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  10% 650/6500 [33:04<4:57:36,  3.05s/it, avr_loss=0.00726]\n",
      "epoch 2/10\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 1, epoch: 2\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 1, epoch: 2\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 1, epoch: 2\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 1, epoch: 2\n",
      "steps:  10% 653/6500 [33:08<4:56:43,  3.04s/it, avr_loss=0.00723]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 650. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "steps:  12% 800/6500 [39:43<4:43:01,  2.98s/it, avr_loss=0.006]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 800\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  15% 1000/6500 [50:09<4:35:53,  3.01s/it, avr_loss=0.00714]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 1000\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:33,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  18% 1200/6500 [59:48<4:24:09,  2.99s/it, avr_loss=0.00716]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 1200\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  20% 1300/6500 [1:04:56<4:19:45,  3.00s/it, avr_loss=0.00704]\n",
      "saving checkpoint: /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000002.safetensors\n",
      "INFO:utils.train_utils:\n",
      "INFO:utils.train_utils:saving state at epoch 2\n",
      "INFO:accelerate.accelerator:Saving current state to /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000002-state\n",
      "INFO:accelerate.checkpointing:Model weights saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000002-state/model.safetensors\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 1300. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "INFO:accelerate.checkpointing:Optimizer state saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000002-state/optimizer.bin\n",
      "INFO:accelerate.checkpointing:Scheduler state saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000002-state/scheduler.bin\n",
      "INFO:accelerate.checkpointing:Sampler state for dataloader 0 saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000002-state/sampler.bin\n",
      "INFO:accelerate.checkpointing:Random states saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000002-state/random_states_0.pkl\n",
      "\n",
      "epoch 3/10\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 2, epoch: 3\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 2, epoch: 3\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 2, epoch: 3\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 2, epoch: 3\n",
      "steps:  22% 1400/6500 [1:09:37<4:13:38,  2.98s/it, avr_loss=0.0069]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 1400\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  25% 1600/6500 [1:19:41<4:04:03,  2.99s/it, avr_loss=0.0058]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 1600\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  28% 1800/6500 [1:29:51<3:54:37,  3.00s/it, avr_loss=0.00462]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 1800\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  30% 1950/6500 [1:36:57<3:46:13,  2.98s/it, avr_loss=0.00415]\n",
      "epoch 4/10\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 3, epoch: 4\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 3, epoch: 4\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 3, epoch: 4\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 3, epoch: 4\n",
      "steps:  30% 1953/6500 [1:37:01<3:45:54,  2.98s/it, avr_loss=0.00415]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 1950. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "steps:  31% 2000/6500 [1:39:10<3:43:09,  2.98s/it, avr_loss=0.00423]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 2000\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  34% 2200/6500 [1:48:56<3:32:54,  2.97s/it, avr_loss=0.00397]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 2200\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  37% 2400/6500 [1:59:35<3:24:17,  2.99s/it, avr_loss=0.00482]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 2400\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  40% 2600/6500 [2:08:52<3:13:19,  2.97s/it, avr_loss=0.00493]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 2600\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  40% 2600/6500 [2:10:03<3:15:04,  3.00s/it, avr_loss=0.00494]\n",
      "saving checkpoint: /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000004.safetensors\n",
      "INFO:utils.train_utils:\n",
      "INFO:utils.train_utils:saving state at epoch 4\n",
      "INFO:accelerate.accelerator:Saving current state to /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000004-state\n",
      "INFO:accelerate.checkpointing:Model weights saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000004-state/model.safetensors\n",
      "INFO:accelerate.checkpointing:Optimizer state saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000004-state/optimizer.bin\n",
      "INFO:accelerate.checkpointing:Scheduler state saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000004-state/scheduler.bin\n",
      "INFO:accelerate.checkpointing:Sampler state for dataloader 0 saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000004-state/sampler.bin\n",
      "INFO:accelerate.checkpointing:Random states saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000004-state/random_states_0.pkl\n",
      "INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 2600\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 2600. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "\n",
      "epoch 5/10\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 4, epoch: 5\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 4, epoch: 5\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 4, epoch: 5\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 4, epoch: 5\n",
      "steps:  43% 2800/6500 [2:19:13<3:03:58,  2.98s/it, avr_loss=0.00715]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 2800\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  46% 3000/6500 [2:29:41<2:54:38,  2.99s/it, avr_loss=0.00769]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 3000\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  49% 3200/6500 [2:39:50<2:44:50,  3.00s/it, avr_loss=0.00776]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 3200\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  50% 3250/6500 [2:43:14<2:43:14,  3.01s/it, avr_loss=0.00773]\n",
      "epoch 6/10\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 5, epoch: 6\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 5, epoch: 6\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 5, epoch: 6\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 5, epoch: 6\n",
      "steps:  50% 3251/6500 [2:43:21<2:43:15,  3.02s/it, avr_loss=0.00775]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 3250. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "steps:  52% 3400/6500 [2:49:35<2:34:38,  2.99s/it, avr_loss=0.00538]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 3400\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  55% 3600/6500 [2:59:22<2:24:29,  2.99s/it, avr_loss=0.00323]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 3600\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  58% 3800/6500 [3:10:03<2:15:02,  3.00s/it, avr_loss=0.00319]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 3800\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  60% 3900/6500 [3:15:21<2:10:14,  3.01s/it, avr_loss=0.00321]\n",
      "saving checkpoint: /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000006.safetensors\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 3900. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "INFO:utils.train_utils:\n",
      "INFO:utils.train_utils:saving state at epoch 6\n",
      "INFO:accelerate.accelerator:Saving current state to /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000006-state\n",
      "INFO:accelerate.checkpointing:Model weights saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000006-state/model.safetensors\n",
      "INFO:accelerate.checkpointing:Optimizer state saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000006-state/optimizer.bin\n",
      "INFO:accelerate.checkpointing:Scheduler state saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000006-state/scheduler.bin\n",
      "INFO:accelerate.checkpointing:Sampler state for dataloader 0 saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000006-state/sampler.bin\n",
      "INFO:accelerate.checkpointing:Random states saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000006-state/random_states_0.pkl\n",
      "\n",
      "epoch 7/10\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 6, epoch: 7\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 6, epoch: 7\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 6, epoch: 7\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 6, epoch: 7\n",
      "steps:  62% 4000/6500 [3:19:52<2:04:55,  3.00s/it, avr_loss=0.00309]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 4000\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  65% 4200/6500 [3:29:33<1:54:45,  2.99s/it, avr_loss=0.00311]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 4200\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  68% 4400/6500 [3:39:51<1:44:55,  3.00s/it, avr_loss=0.00262]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 4400\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  70% 4550/6500 [3:47:25<1:37:27,  3.00s/it, avr_loss=0.00228]\n",
      "epoch 8/10\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 7, epoch: 8\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 7, epoch: 8\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 7, epoch: 8\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 7, epoch: 8\n",
      "steps:  70% 4555/6500 [3:47:32<1:37:09,  3.00s/it, avr_loss=0.00226]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 4550. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "steps:  71% 4600/6500 [3:50:00<1:35:00,  3.00s/it, avr_loss=0.00234]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 4600\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  74% 4800/6500 [3:59:45<1:24:54,  3.00s/it, avr_loss=0.00215]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 4800\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  77% 5000/6500 [4:10:35<1:15:10,  3.01s/it, avr_loss=0.0022]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 5000\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  80% 5200/6500 [4:19:19<1:04:49,  2.99s/it, avr_loss=0.00191]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 5200\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  80% 5200/6500 [4:20:29<1:05:07,  3.01s/it, avr_loss=0.00191]\n",
      "saving checkpoint: /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000008.safetensors\n",
      "INFO:utils.train_utils:\n",
      "INFO:utils.train_utils:saving state at epoch 8\n",
      "INFO:accelerate.accelerator:Saving current state to /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000008-state\n",
      "INFO:accelerate.checkpointing:Model weights saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000008-state/model.safetensors\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 5200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "INFO:accelerate.checkpointing:Optimizer state saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000008-state/optimizer.bin\n",
      "INFO:accelerate.checkpointing:Scheduler state saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000008-state/scheduler.bin\n",
      "INFO:accelerate.checkpointing:Sampler state for dataloader 0 saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000008-state/sampler.bin\n",
      "INFO:accelerate.checkpointing:Random states saved in /content/drive/Shareddrives/StableDiffusion/Lora/test_vivi_wan_i2v/test_vivi-000008-state/random_states_0.pkl\n",
      "INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 5200\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "\n",
      "epoch 9/10\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 8, epoch: 9\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 8, epoch: 9\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 8, epoch: 9\n",
      "INFO:dataset.image_video_dataset:epoch is incremented. current_epoch: 8, epoch: 9\n",
      "steps:  83% 5400/6500 [4:30:20<55:04,  3.00s/it, avr_loss=0.00196]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 5400\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.31s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  86% 5600/6500 [4:40:14<45:02,  3.00s/it, avr_loss=0.00183]INFO:hv_train_network:\n",
      "INFO:hv_train_network:generating sample images at step / ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ ã‚¹ãƒ†ãƒƒãƒ—: 5600\n",
      "INFO:hv_train_network:prompt: vivi, a woman wearing a black dress, holding a pen in her hand, standing in front of a wall with Chinese writing on it.\n",
      "INFO:hv_train_network:height: 512\n",
      "INFO:hv_train_network:width: 512\n",
      "INFO:hv_train_network:frame count: 25\n",
      "INFO:hv_train_network:sample steps: 20\n",
      "INFO:hv_train_network:guidance scale: 6.0\n",
      "INFO:hv_train_network:discrete flow shift: 14.5\n",
      "INFO:hv_train_network:negative prompt: è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\n",
      "INFO:hv_train_network:cfg scale: None\n",
      "INFO:hv_train_network:image path: /content/imageanime.png\n",
      "\n",
      "Sampling timesteps for prompt 1:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Sampling timesteps for prompt 1:   5% 1/20 [00:03<01:02,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  10% 2/20 [00:06<00:59,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  15% 3/20 [00:09<00:56,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  20% 4/20 [00:13<00:52,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  25% 5/20 [00:16<00:49,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  30% 6/20 [00:19<00:46,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  35% 7/20 [00:23<00:42,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  40% 8/20 [00:26<00:39,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  45% 9/20 [00:29<00:36,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  50% 10/20 [00:32<00:32,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  55% 11/20 [00:36<00:29,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  60% 12/20 [00:39<00:26,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  65% 13/20 [00:42<00:23,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  70% 14/20 [00:46<00:19,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  75% 15/20 [00:49<00:16,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  80% 16/20 [00:52<00:13,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  85% 17/20 [00:56<00:09,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  90% 18/20 [00:59<00:06,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1:  95% 19/20 [01:02<00:03,  3.30s/it]\u001b[A\n",
      "Sampling timesteps for prompt 1: 100% 20/20 [01:05<00:00,  3.30s/it]\n",
      "INFO:__main__:Decoding video from latents: torch.Size([16, 7, 64, 64])\n",
      "INFO:__main__:Decoding complete\n",
      "steps:  89% 5768/6500 [4:49:09<36:41,  3.01s/it, avr_loss=0.00198]"
     ]
    }
   ],
   "source": [
    "#@title â³ 3. Training\n",
    "%cd /content/musubi-tuner\n",
    "run_cache = True #@param {type:\"boolean\"}\n",
    "if run_cache:\n",
    "  !{arg_latents_config}\n",
    "  !{arg_text_encoder_config}\n",
    "!{arg}\n",
    "\n",
    "AutoDisconect = True # @param {\"type\":\"boolean\"}\n",
    "if AutoDisconect:\n",
    "  from time import sleep\n",
    "  sleep(3*60)\n",
    "  from google.colab import runtime\n",
    "  runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "YXK9gCuIvzvs",
    "HYytXyzlj6PT"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
