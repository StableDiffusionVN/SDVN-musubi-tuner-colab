{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8KQYvGDO7cg"
   },
   "outputs": [],
   "source": [
    "# @title Script\n",
    "\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from unittest.mock import patch\n",
    "from IPython.display import clear_output,display, HTML\n",
    "from itertools import islice\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from transformers.dynamic_module_utils import get_imports\n",
    "\n",
    "import io, base64, json, yaml, toml\n",
    "import numpy as np\n",
    "import requests, copy, os, torch, gc, re\n",
    "import torch.amp.autocast_mode\n",
    "\n",
    "gpu_name = torch.cuda.get_device_name()\n",
    "print(gpu_name)\n",
    "if 'A100' in gpu_name:\n",
    "  os.environ['TORCH_CUDA_ARCH_LIST'] = '8.0'\n",
    "if 'L4' in gpu_name:\n",
    "  os.environ['TORCH_CUDA_ARCH_LIST'] = '8.9'\n",
    "if 'T4' in gpu_name:\n",
    "  os.environ['TORCH_CUDA_ARCH_LIST'] = '7.5'\n",
    "\n",
    "version = \"large\"\n",
    "device = torch.device(torch.cuda.current_device())\n",
    "\n",
    "#API\n",
    "model_list = {\n",
    "    \"APIGemini | 2.5 Pro\": \"gemini-2.5-pro\",\n",
    "    \"APIGemini | 2.5 Flash\": \"gemini-2.5-flash\",\n",
    "    \"APIGemini | 2.5 Flash Lite\": \"gemini-2.5-flash-lite\",\n",
    "    \"APIOpenAI | GPT 5\": \"gpt-5\",\n",
    "    \"APIOpenAI | GPT 5-mini\": \"gpt-5-mini\",\n",
    "    \"APIOpenAI | GPT 5-nano\": \"gpt-5-nano\",\n",
    "}\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/StableDiffusionVN/SDVN-WebUI/refs/heads/main/model_lib.json\"\n",
    "response = requests.get(url)\n",
    "model_train_list = json.loads(response.text)\n",
    "\n",
    "def encode_image(image):\n",
    "    with io.BytesIO() as image_buffer:\n",
    "        image.save(image_buffer, format=\"PNG\")\n",
    "        image_buffer.seek(0)\n",
    "        encoded_image = base64.b64encode(image_buffer.read()).decode('utf-8')\n",
    "    return encoded_image\n",
    "\n",
    "def api_check():\n",
    "    api_file = os.path.join(data_dir,\"Setting/API_key_for_sdvn_comfy_node.json\")\n",
    "    if os.path.exists(api_file):\n",
    "        with open(api_file, 'r', encoding='utf-8') as f:\n",
    "            api_list = json.load(f)\n",
    "        return api_list\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def gemini_caption_video(video_path,length:int, APIkey, Caption, prompt):\n",
    "    video_file_name = video_path\n",
    "    video_bytes = open(video_file_name, 'rb').read()\n",
    "    if APIkey == \"\":\n",
    "        api_list = api_check()\n",
    "        if api_check() != None:\n",
    "            if \"Gemini\" in Caption:\n",
    "                APIkey =  api_list[\"Gemini\"]\n",
    "    model_name = model_list[Caption]\n",
    "    prompt += f\"Can you summarize this video?, limit {length} words, only send me the answer, Always return English. \"\n",
    "    if 'Gemini' in Caption:\n",
    "        client = genai.Client(api_key=APIkey)\n",
    "        response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(\n",
    "                        parts=[\n",
    "                            types.Part(text = prompt),\n",
    "                            types.Part(\n",
    "                                inline_data=types.Blob(data=video_bytes, mime_type='video/mp4')\n",
    "                            )]))\n",
    "        answer = response.text\n",
    "    return answer.strip()\n",
    "\n",
    "def api_caption(image, length:int, APIkey, Caption, prompt):\n",
    "    if APIkey == \"\":\n",
    "        api_list = api_check()\n",
    "        if api_check() != None:\n",
    "            if \"Gemini\" in Caption:\n",
    "                APIkey =  api_list[\"Gemini\"]\n",
    "            if \"OpenAI\" in Caption:\n",
    "                APIkey =  api_list[\"OpenAI\"]\n",
    "    model_name = model_list[Caption]\n",
    "    prompt += f\"Picture description, Send the description on demand, limit {length} words, only send me the answer, Always return English. \"\n",
    "    if 'Gemini' in Caption:\n",
    "        client = genai.Client(api_key=APIkey)\n",
    "        response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=[prompt, image])\n",
    "        answer = response.text\n",
    "    if \"OpenAI\" in Caption:\n",
    "        answer = \"\"\n",
    "        client = OpenAI(\n",
    "            api_key=APIkey)\n",
    "        if image != None:\n",
    "            image = encode_image(image)\n",
    "            prompt = [{\"type\": \"text\", \"text\": prompt, }, {\n",
    "                \"type\": \"image_url\", \"image_url\": {\"url\":  f\"data:image/jpeg;base64,{image}\"}, },]\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt }]\n",
    "        stream = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content is not None:\n",
    "                answer += chunk.choices[0].delta.content\n",
    "        if image != None:\n",
    "            answer = answer.split('return True')[-1]\n",
    "    return answer.strip()\n",
    "\n",
    "def clean_directory(directory):\n",
    "  supported_types = [\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".safetensors\"]\n",
    "  for item in os.listdir(directory):\n",
    "      file_path = os.path.join(directory, item)\n",
    "      if os.path.isfile(file_path):\n",
    "          file_ext = os.path.splitext(item)[1]\n",
    "          if file_ext not in supported_types:\n",
    "              print(f\"Deleting file {item} from {directory}\")\n",
    "              os.remove(file_path)\n",
    "      elif os.path.isdir(file_path):\n",
    "          clean_directory(file_path)\n",
    "\n",
    "#Florence\n",
    "\n",
    "version = \"large\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float3\n",
    "\n",
    "def fixed_get_imports(filename: str | os.PathLike) -> list[str]:\n",
    "    \"\"\"Workaround for FlashAttention\"\"\"\n",
    "    if os.path.basename(filename) != \"modeling_florence2.py\":\n",
    "        return get_imports(filename)\n",
    "    imports = get_imports(filename)\n",
    "    return imports\n",
    "\n",
    "def load_model(version, device):\n",
    "    from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "    model_dir = \"/content/Model\"\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "\n",
    "    identifier = \"microsoft/Florence-2-\" + version\n",
    "\n",
    "    with patch(\"transformers.dynamic_module_utils.get_imports\", fixed_get_imports):\n",
    "        model = AutoModelForCausalLM.from_pretrained(identifier, torch_dtype=torch_dtype, cache_dir=model_dir, trust_remote_code=True).to(device)\n",
    "        processor = AutoProcessor.from_pretrained(identifier, cache_dir=model_dir, trust_remote_code=True)\n",
    "\n",
    "    model = model.to(device)\n",
    "    return (model, processor)\n",
    "\n",
    "def load(version, device):\n",
    "  if 'processor' not in globals():\n",
    "    global model, processor\n",
    "    model, processor = load_model(version, device)\n",
    "\n",
    "def run_example(task_prompt, image, max_new_tokens, num_beams, do_sample, text_input=None):\n",
    "    if text_input is None:\n",
    "        prompt = task_prompt\n",
    "    else:\n",
    "        prompt = task_prompt + text_input\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device, torch_dtype)\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        early_stopping=False,\n",
    "        do_sample=do_sample,\n",
    "        num_beams=num_beams,\n",
    "    )\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "        generated_text,\n",
    "        task=task_prompt,\n",
    "        image_size=(image.width, image.height)\n",
    "    )\n",
    "\n",
    "    return parsed_answer\n",
    "\n",
    "def florence_caption(task_prompt, image, max_new_tokens = 1024, num_beams = 3, do_sample = False, fill_mask = False, text_input=None):\n",
    "    result = run_example(task_prompt, image, max_new_tokens, num_beams, do_sample)\n",
    "    return result[task_prompt].replace(\"\\n\", \"\")\n",
    "\n",
    "#Caption\n",
    "\n",
    "def caption_dir(image_dir,prompt, videodir = False):\n",
    "  if videodir == False:\n",
    "    if Caption_Image == 'Florence':\n",
    "      load(version, device)\n",
    "  for img_file in os.listdir(image_dir):\n",
    "      file_path = os.path.join(image_dir, img_file)\n",
    "      if os.path.isdir(file_path) :\n",
    "          caption_dir(file_path,prompt)\n",
    "      if videodir == False:\n",
    "        if img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\")):\n",
    "            img_path = os.path.join(image_dir, img_file)\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if Caption_Image == 'Florence':\n",
    "              cap = florence_caption(prompt[0],image).replace('The image shows','')\n",
    "            else:\n",
    "              cap = api_caption(image, prompt[2], APIkey, Caption_Image, API_Prompt)\n",
    "            txt_path = os.path.join(image_dir, f\"{os.path.splitext(img_file)[0]}{extension}\")\n",
    "            with open(txt_path, \"w\") as f:\n",
    "                f.write(cap)\n",
    "            print(f\"Miêu tả của ảnh {img_file}: {cap}\")\n",
    "      else:\n",
    "        if img_file.lower().endswith(\".mp4\"):\n",
    "            video_path = os.path.join(image_dir, img_file)\n",
    "            cap = gemini_caption_video(video_path, prompt[2], APIkey, Caption_Video, API_Prompt)\n",
    "            txt_path = os.path.join(image_dir, f\"{os.path.splitext(img_file)[0]}{extension}\")\n",
    "            with open(txt_path, \"w\") as f:\n",
    "                f.write(cap)\n",
    "            print(f\"Miêu tả của video {img_file}: {cap}\")\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        contents = f.read()\n",
    "    return contents\n",
    "\n",
    "def write_file(filename, contents):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(contents)\n",
    "\n",
    "def process_tags(filename, custom_tag, append, remove_tag):\n",
    "    contents = read_file(filename)\n",
    "    if remove_tag:\n",
    "      contents = contents.replace(custom_tag, \"\")\n",
    "    else:\n",
    "      tags = [tag.strip() for tag in contents.split(',')]\n",
    "      custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
    "      for custom_tag in custom_tags:\n",
    "          custom_tag = custom_tag.replace(\"_\", \" \")\n",
    "          if custom_tag not in tags:\n",
    "              if append:\n",
    "                  tags.append(custom_tag)\n",
    "              else:\n",
    "                  tags.insert(0, custom_tag)\n",
    "      contents = ', '.join(tags)\n",
    "    write_file(filename, contents)\n",
    "\n",
    "def check_dir(image_dir):\n",
    "  if not any([filename.endswith(extension) for filename in os.listdir(image_dir)]):\n",
    "      for filename in os.listdir(image_dir):\n",
    "          if filename.endswith(((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\"))):\n",
    "              open(\n",
    "                  os.path.join(image_dir, filename.split(\".\")[0] + extension),\n",
    "                  \"w\",\n",
    "              ).close()\n",
    "\n",
    "def process_dir(image_dir, tag, append, remove_tag):\n",
    "  check_dir(image_dir)\n",
    "  for filename in os.listdir(image_dir):\n",
    "      file_path = os.path.join(image_dir, filename)\n",
    "      if os.path.isdir(file_path) :\n",
    "          print(filename)\n",
    "          process_dir(file_path, tag, append, remove_tag)\n",
    "      elif filename.endswith(extension):\n",
    "          process_tags(file_path, tag, append, remove_tag)\n",
    "\n",
    "def add_forder_name(folder):\n",
    "  for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    if os.path.isdir(file_path):\n",
    "      folder_name = os.path.basename(file_path)\n",
    "      try:\n",
    "          steps, name = folder_name.split('_', 1)\n",
    "          steps = int(steps)\n",
    "      except ValueError:\n",
    "          name = folder_name\n",
    "      name = name.replace(\"/\", \", \")\n",
    "      process_dir(file_path, name, False, False)\n",
    "      add_forder_name(file_path)\n",
    "\n",
    "def get_steps(folder):\n",
    "    folder_name = os.path.basename(folder)\n",
    "    try:\n",
    "        steps, name = folder_name.split('_', 1)\n",
    "        steps = int(steps)\n",
    "    except ValueError:\n",
    "        steps = Steps\n",
    "        name = folder_name\n",
    "    return steps, name\n",
    "\n",
    "def check_txt(image_dir):\n",
    "    txt_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.txt')]\n",
    "    for filename in os.listdir(image_dir):\n",
    "        file_path = os.path.join(image_dir, filename)\n",
    "        if os.path.isdir(file_path):\n",
    "            txt_files += check_txt(file_path)\n",
    "    return txt_files\n",
    "\n",
    "def random_sample(folder, control_folder = None):\n",
    "  import random\n",
    "  txt_files = check_txt(folder)\n",
    "  rd_file = random.choice(txt_files)\n",
    "  if control_folder != None:\n",
    "      control_path = rd_file.replace(folder, control_folder).replace(\".txt\", \"_0.png\")\n",
    "  else:\n",
    "      control_path = \"\"\n",
    "  try:\n",
    "    sample = read_file(random.choice(txt_files))\n",
    "    sample = sample.replace('\"', r'\\\"')\n",
    "  except IndexError:\n",
    "    sample = \"girl portrait, smile\"\n",
    "  return [sample, control_path]\n",
    "\n",
    "def get_supported_images(folder):\n",
    "  import glob\n",
    "  supported_extensions = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\")\n",
    "  list_img = [file for ext in supported_extensions for file in glob.glob(f\"{folder}/*{ext}\")]\n",
    "  for img_file in os.listdir(folder):\n",
    "      file_path = os.path.join(folder, img_file)\n",
    "      if os.path.isdir(file_path) :\n",
    "          list_img = list_img + get_supported_images(file_path)\n",
    "  return list_img\n",
    "\n",
    "def check_folder_train(folder):\n",
    "    if len(get_supported_images(folder)) > 0:\n",
    "      folder_dic = {\n",
    "        \"path\": folder,\n",
    "      }\n",
    "      print('=====================')\n",
    "      print(f'Thư mục train: {folder_dic[\"path\"]}')\n",
    "      print(f'  Số lượng ảnh: {len(get_supported_images(folder_dic[\"path\"]))}')\n",
    "      print('=====================')\n",
    "    else:\n",
    "      print(f\"Thư mục [ {folder} ] có thể không chứa ảnh được hỗ trợ, hãy kiểm tra lại (.png, .jpg, .jpeg, .webp, .bmp, .JPG, .JPEG, .PNG)\")\n",
    "\n",
    "def check_dir_image(image_dir):\n",
    "  if not any([filename.endswith(((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\", \".mp4\", \".mov\"))) for filename in os.listdir(image_dir)]):\n",
    "    return False\n",
    "  else:\n",
    "    return True\n",
    "\n",
    "def check_sub_dir(image_dir):\n",
    "    list_dir = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        file_path = os.path.join(image_dir, filename)\n",
    "        if os.path.isdir(file_path):\n",
    "            list_dir += check_sub_dir(file_path)\n",
    "    if check_dir_image(image_dir):\n",
    "      list_dir += [image_dir]\n",
    "    return list_dir\n",
    "\n",
    "def repeat_dir(dir,num_repeats):\n",
    "    dir_name = dir.split('/')[-1]\n",
    "    try:\n",
    "        r = int(dir_name.split('_')[0])\n",
    "    except:\n",
    "        r = num_repeats\n",
    "    return r\n",
    "\n",
    "def dic2arg(config:dict):\n",
    "  arg = ''\n",
    "  for value in config:\n",
    "    arg += f'{value if str(config[value]) != \"False\" else \"\"} {\"\" if type(config[value]) == bool else config[value]} '\n",
    "  return arg\n",
    "\n",
    "def civit_downlink(link):\n",
    "  !wget {link} -q -O model.html\n",
    "  try:\n",
    "      # Mở tệp và đọc nội dung\n",
    "      with open('model.html', 'r', encoding='utf-8') as file:\n",
    "          html_content = file.read()\n",
    "      pattern = r'\"modelVersionId\":(\\d+),'\n",
    "      model_id = re.findall(pattern, html_content)\n",
    "      if model_id:\n",
    "        api_link = f'https://civitai.com/api/download/models/{model_id[0]}'\n",
    "        print(f'Download model id_link: {api_link}')\n",
    "        return api_link\n",
    "      else:\n",
    "          return \"Không tìm thấy đoạn nội dung phù hợp.\"\n",
    "  except requests.RequestException as e:\n",
    "      return f\"Lỗi khi tải trang: {e}\"\n",
    "\n",
    "def check_link(link):\n",
    "  if 'huggingface.co' in link:\n",
    "    if 'blob' in link:\n",
    "      link = link.replace('blob', 'resolve')\n",
    "  if 'civitai.com' in link:\n",
    "    if 'civitai.com/models' in link:\n",
    "      link = civit_downlink(link)\n",
    "    link = link+'?token=8c7337ac0c39fe4133ae19a3d65b806f'\n",
    "  return link\n",
    "\n",
    "def aria_down(link,path,name, over = False):\n",
    "  print(link)\n",
    "  link = check_link(link)\n",
    "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {'--allow-overwrite=true' if over else ''} {link} -d  {path} -o {name}\n",
    "\n",
    "def download_lib(model):\n",
    "  if 'https:' in model:\n",
    "    model = model.replace('&', '\\&')\n",
    "    aria_down(model,model_folder,\"model.safetensors\", True)\n",
    "    model_path = f\"{model_folder}/model.safetensors\"\n",
    "  elif '/content/' in model:\n",
    "    model_path = model\n",
    "  return model_path\n",
    "\n",
    "def hug_down(link,path):\n",
    "  name = path.split('/')[-1]\n",
    "  folder = path.split(name)[0]\n",
    "  if \"blob\" in link:\n",
    "    link = link.replace(\"blob\",\"resolve\")\n",
    "  !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -s 16 -k 1M {link} -d {folder} -o {name}\n",
    "\n",
    "def model_path(model):\n",
    "  model_name = model\n",
    "  model_name = model_train_list[model].split('/')[-1]\n",
    "  model_path = os.path.join(model_folder,model_name)\n",
    "  if not os.path.exists(model_path):\n",
    "    hug_down(model_train_list[model],model_path)\n",
    "  return model_path\n",
    "\n",
    "def rename_ext_file(img_list, ext):\n",
    "    pattern = re.compile(r\"_\\d+\\.png$\", re.IGNORECASE)  # match \"_<số>.png\"\n",
    "    for img_file in img_list:\n",
    "        if not pattern.search(img_file):\n",
    "            os.rename(img_file, f\"{os.path.splitext(img_file)[0]}{ext}\")\n",
    "\n",
    "def config_control_image(image_dir,control_dir):\n",
    "    rename_ext_file(get_supported_images(image_dir), \".jpg\")\n",
    "    rename_ext_file(get_supported_images(control_dir), \"_0.png\")\n",
    "\n",
    "def image_size(image_path, max_size=1536, qwensize = False):\n",
    "    import math\n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "    if qwensize:\n",
    "        scale_ratio = math.sqrt(1024*1024 / (width*height))\n",
    "    else:\n",
    "        if max(width, height) <= max_size:\n",
    "            return width, height\n",
    "        scale_ratio = max_size / max(width, height)\n",
    "    new_width = int(width * scale_ratio)\n",
    "    new_height = int(height * scale_ratio)\n",
    "    return new_width, new_height"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
